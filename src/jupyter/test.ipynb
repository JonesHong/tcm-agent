{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# ChatOllama.c\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.2,\n",
    "    base_url=\"http://192.168.1.246:11434/\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"根據使用者提供的訊息，判斷當前對話屬於舌診、中醫十問(體質、問診、十問)或其他中醫相關提問。\"\n",
    "        \"\\n如果是舌診、舌頭，回應『舌診』；\"\n",
    "        \"如果是中醫十問(體質、問診、十問)，回應『中醫十問』；\"\n",
    "        \"如果是其他，回應『其他』。\\n\\n例子：\\n\"\n",
    "        \"使用者訊息：「我最近頭暈、噁心、想吐，應該怎麼辦？」\\n回應：其他\\n\\n\"\n",
    "        \"使用者訊息：「我最近舌頭顏色變了，有點頭暈、噁心，能幫我看看舌頭嗎？」\\n回應：舌診\\n\\n\"\n",
    "        \"使用者訊息：「我平時容易出汗，手腳冰涼，這是什麼體質？」\\n回應：中醫十問\",\n",
    "    ),\n",
    "    (\"user\", \"判斷以下意圖。\\n我心跳常常慢一拍的感覺，胸口很難受\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"根據使用者提供的訊息，判斷他是否有意圖進行中醫舌診。如果有意圖，回答『是』，否則回答『否』。\",\n",
    "    ),\n",
    "    (\"user\", \"判斷以下意圖。\\n我最近頭暈、噁心、想吐，應該怎麼辦？\"),\n",
    "    (\"ai\", \"否\"),\n",
    "    (\"user\", \"判斷以下意圖。\\n我最近舌頭顏色變了，有點頭暈、噁心，能幫我看看舌頭嗎？\"),\n",
    "    (\"ai\", \"是\"),\n",
    "    (\"user\", \"判斷以下意圖。\\n我心跳常常慢一拍的感覺，胸口很難受\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AIMessage(\"否\").dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"請將使用者的整句話濃縮總結成一個不超過30字的重點句子。\\n例如，使用者訊息：'我最近經常頭痛，尤其是在下午，工作壓力大，睡眠不好。'，濃縮總結應為：'工作壓力大導致下午頭痛和睡眠不足。\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"根据周某某的症状和检查结果，我认为他的主要问题是耳聋，而他之前使用过益气聪明汤等治疗方法没有见效。   结合他的病史，感冒后出现了汗证，这可能导致了体内虚弱、肺脏受损等情况。同时，他的舌色淡红，苔薄白，脉细软无力，也表明他有气血不足的问题。  因此，我给出的中医诊断是：  **主症：耳聋**  **次症：心悸乏力、畏寒感**  **病因**:感冒后出现汗证导致体 内虚弱  根据以上的分析，我的处方建议如下：  ***药物组合：** \\t+向肺补气之品，如沙参、黄芪 \\t+益血养阴之品，如枸杞子、熟 地黄 \\t+散风清热之品，如薄荷、三棱 \\t+补益心脉之品，如当归、川楝子 ***方剂：**向肺补气饮散加减服用  具体的煎法和量级需要根据个体情况调整。  以上是我的诊断和处方建议。希望能给周某某带来一些帮助！\\n\\n整句話濃縮總結成一個不超過30字的重點句子\"\n",
    "        ),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"請將使用者的整句話濃縮總結成一個不超過30字的重點句子。\\n例如，使用者訊息：'我最近經常頭痛，尤其是在下午，工作壓力大，睡眠不好。'，濃縮總結應為：'工作壓力大導致下午頭痛和睡眠不足。\",\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"根据周某某的症状和检查结果，我认为他的主要问题是耳聋，而他之前使用过益气聪明汤等治疗方法没有见效。   结合他的病史，感冒后出现了汗证，这可能导致了体内虚弱、肺脏受损等情况。同时，他的舌色淡红，苔薄白，脉细软无力，也表明他有气血不足的问题。  因此，我给出的中医诊断是：  **主症：耳聋**  **次症：心悸乏力、畏寒感**  **病因**:感冒后出现汗证导致体 内虚弱  根据以上的分析，我的处方建议如下：  ***药物组合：** \\t+向肺补气之品，如沙参、黄芪 \\t+益血养阴之品，如枸杞子、熟 地黄 \\t+散风清热之品，如薄荷、三棱 \\t+补益心脉之品，如当归、川楝子 ***方剂：**向肺补气饮散加减服用  具体的煎法和量级需要根据个体情况调整。  以上是我的诊断和处方建议。希望能给周某某带来一些帮助！\\n\\n整句話濃縮總結成一個不超過30字的重點句子\"\n",
    "        ),\n",
    "]\n",
    "## 計算 token per seconds\n",
    "is_first_output = False\n",
    "token_list = []\n",
    "first_time = None\n",
    "for token in llm.stream(messages):\n",
    "    # print(token.content)\n",
    "    if not is_first_output:\n",
    "        is_first_output= True\n",
    "        first_time = time.time() - start_time\n",
    "    token_list.append(token.content)\n",
    "response = \"\".join(token_list)\n",
    "execution_time = time.time() - start_time\n",
    "tps_time = len(token_list) / (execution_time - first_time)\n",
    "tps_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "brainstorm_llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.2,\n",
    "    base_url=\"http://192.168.1.246:11434/\"\n",
    "    # other params...\n",
    "    ,\n",
    "    metadata={\"name\":\"brainstorm_llm\"}\n",
    ")\n",
    "brainstorm_messages = [\n",
    "    (\"system\", \"You are an assistant tasked with brainstorming ideas for brainstorming ideas for \\\n",
    "    a chapter in a story. You should brainstorm ideas relevant to the plotline and in accordance with \\\n",
    "     the users wishes for the next chapter. You should brainstorm multiple ideas for what the chapter could \\\n",
    "     be about, making detailed descriptions of all your ideas. Do not return anything other than a numbered list of ideas.\"),\n",
    "     (\"human\", \"{summary_request}\"),\n",
    "     (\"human\", \"{detail_request}\"),\n",
    "     (\"human\", \"{style_request}\"),\n",
    "     (\"human\", \"This is the summary of the story up to this point: {story_summary}\"),\n",
    "     (\"human\", \"I would like to {action}. Can you please help me brainstorm ideas for that?\")\n",
    "]\n",
    "\n",
    "\n",
    "brainstorm_prompt = ChatPromptTemplate.from_messages(brainstorm_messages)\n",
    "brainstorm_chain = brainstorm_prompt | brainstorm_llm | StrOutputParser()\n",
    "\n",
    "\n",
    "brainstorm_ideas = brainstorm_chain.invoke({'story_summary':'chapters_summary','action':'user_message','summary_request':\"state['summary_request']\", \\\n",
    "                                                'detail_request':\"state['detail_request']\",'style_request':\"state['style_request']\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainstorm_ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "\n",
    "# 抽象的提示处理服务类，供其他具体服务类继承\n",
    "from abc import ABC, abstractmethod\n",
    "import copy\n",
    "from src.services.agent_service.ollama_llm import llm\n",
    "from src.schemas._enum import MessageType\n",
    "\n",
    "from src.utils.decorators.singleton import singleton\n",
    "from src.utils.decorators.inject_llm import inject_llm\n",
    "\n",
    "\n",
    "class AbstractPromptService(ABC):\n",
    "\n",
    "    # 用户输入提示前缀\n",
    "    @abstractmethod\n",
    "    def user_prompt_prefix(self):\n",
    "        pass\n",
    "\n",
    "    # 原型消息列表\n",
    "    @abstractmethod\n",
    "    def messages_list_proto(self):\n",
    "        pass\n",
    "\n",
    "    # 组合用户输入为消息列表\n",
    "    @abstractmethod\n",
    "    def assemble_messages(self, user_input):\n",
    "        pass\n",
    "\n",
    "    # 调用 LLM 并处理响应\n",
    "    @abstractmethod\n",
    "    def invoke(self, user_input):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def messages_history_list(self):\n",
    "        # 返回历史消息列表\n",
    "        return self._messages_history\n",
    "    \n",
    "    def add_to_history(self, message):\n",
    "        # 向历史消息列表中添加新消息\n",
    "        self._messages_history.append(message)\n",
    "\n",
    "\n",
    "# 意图检测启动服务类\n",
    "@singleton\n",
    "@inject_llm(llm)\n",
    "class _IntentDetectionStartupService(AbstractPromptService):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self): \n",
    "        self.value = None\n",
    "        self._messages_history = []  # 初始化历史消息列表\n",
    "        \n",
    "    # 实现抽象属性 user_prompt_prefix\n",
    "    @property\n",
    "    def user_prompt_prefix(self):\n",
    "        return \"請問以下對話屬於舌診、中醫十問或是其他，用簡答。\\n- - - -\\n\"\n",
    "\n",
    "    # 系统提示\n",
    "    @property\n",
    "    def system_prompt(self):\n",
    "        return (\n",
    "            MessageType.SYSTEM.value,\n",
    "            \"根據使用者提供的訊息，判斷當前對話屬於舌診、中醫十問或其他中醫相關提問。\"\n",
    "            \"如果訊息中提到舌診、舌頭，回應『舌診』；\"\n",
    "            \"如果訊息中提到體質、問診、十問，回應『中醫十問』；\"\n",
    "            \"如果訊息中沒有提及上述內容，回應『其他』。\",\n",
    "        )\n",
    "\n",
    "    # 示例对话\n",
    "    @property\n",
    "    def example_prompts(self):\n",
    "        return [\n",
    "            (\n",
    "                MessageType.USER.value,\n",
    "                f\"{self.user_prompt_prefix}我最近頭暈、噁心、想吐，應該怎麼辦？\",\n",
    "            ),\n",
    "            (MessageType.ASSISTANT.value, \"其他\"),\n",
    "            (\n",
    "                MessageType.USER.value,\n",
    "                f\"{self.user_prompt_prefix}我最近舌頭顏色變了，有點頭暈、噁心，能幫我看看舌頭嗎？\",\n",
    "            ),\n",
    "            (MessageType.ASSISTANT.value, \"舌診\"),\n",
    "            (\n",
    "                MessageType.USER.value,\n",
    "                f\"{self.user_prompt_prefix}我平時容易出汗，手腳冰涼，這是什麼體質？\",\n",
    "            ),\n",
    "            (MessageType.ASSISTANT.value, \"中醫十問\"),\n",
    "        ]\n",
    "\n",
    "    # 实现抽象属性 messages_list_proto\n",
    "    @property\n",
    "    def messages_list_proto(self):\n",
    "        # 将 system_prompt 和 example_prompts 合并为完整的消息列表\n",
    "        return [self.system_prompt] + self.example_prompts\n",
    "\n",
    "    # 实现实例方法 assemble_messages\n",
    "    def assemble_messages(self, user_input):\n",
    "        new_messages_list = copy.deepcopy(self.messages_list_proto)\n",
    "        new_entry = (\n",
    "            MessageType.USER.value,\n",
    "            f\"{self.user_prompt_prefix}{user_input}\",\n",
    "        )\n",
    "        new_messages_list.append(new_entry)\n",
    "        # 将新输入的消息添加到历史记录中\n",
    "        self.add_to_history(new_entry)\n",
    "        return new_messages_list\n",
    "\n",
    "    # 实现实例方法调用 LLM 并处理响应\n",
    "    def invoke(self, user_input):\n",
    "        # 组合消息\n",
    "        messages = self.assemble_messages(user_input)\n",
    "        \n",
    "        # 调用 LLM 并获取响应\n",
    "        ai_response = self.llm.invoke(messages)\n",
    "        \n",
    "        # 将 LLM 的响应添加到历史记录中\n",
    "        assistant_response = (MessageType.ASSISTANT.value, ai_response.content)\n",
    "        self.add_to_history(assistant_response)\n",
    "        \n",
    "        # 返回 LLM 的响应\n",
    "        return ai_response\n",
    "\n",
    "\n",
    "# 实例化服务类\n",
    "IntentDetectionStartupService = _IntentDetectionStartupService()\n",
    "\n",
    "# 测试调用\n",
    "ai_response_1 = IntentDetectionStartupService.invoke('我月經已經三個月沒來了，我是更年期了嗎')\n",
    "print(\"AI Response:\", ai_response_1.content)\n",
    "\n",
    "# 重置单例实例\n",
    "IntentDetectionStartupService.reset()\n",
    "\n",
    "ai_response_2 = IntentDetectionStartupService.invoke('刘某某，女，12岁。初春感受风寒邪气，头痛发热，家人自购“平热散”，服药后汗出较多，随后发热消退。但第二天发热恶寒如疟疾之发作，上午一次，下午二次。脉浮略数，舌苔薄白而润。给出中医诊断和处方建议')\n",
    "print(\"AI Response:\", ai_response_2.content)\n",
    "\n",
    "ai_response_3 = IntentDetectionStartupService.invoke('這邊可以幫忙檢查舌頭嗎?')\n",
    "print(\"AI Response:\", ai_response_3.content)\n",
    "print(\"Message History:\", IntentDetectionStartupService.messages_history_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': {'name': 'calculate', 'arguments': {'x': 6, 'y': 9}}}\n",
      "Tool Call Result: 60\n",
      "手動使用工具計算結果：60。\n",
      "這超出我的能力範圍了\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(x: int, y: int) -> int:\n",
    "    \"\"\"返回兩個數字的計算的結果。\"\"\"\n",
    "    res = x * (y + 1)\n",
    "    return res\n",
    "\n",
    "chat_model = ChatOllama(model=\"llama3.1:8b\",temperature=0.2, base_url=\"http://192.168.1.110:11434/\").bind_tools([calculate])\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"你只能根據工具回答。如果工具無法處理使用者問題請回答：＂這超出我的能力範圍了＂\"),\n",
    "    (\"human\", \"請計算 6 和 9 的值。\")\n",
    "    # ('ai','',tool_calls:['w'])\n",
    "]\n",
    "\n",
    "response_1 = chat_model.invoke(messages)\n",
    "\n",
    "# # 確保工具調用的結果被納入回應中\n",
    "# response_1['tool_calls']\n",
    "if 'tool_calls' in response_1.response_metadata['message']:\n",
    "    for tool_call in response_1.response_metadata['message']['tool_calls']:\n",
    "        print(tool_call)\n",
    "        # 假设 calculate 工具的结果是通过 tool_call 的 'result' 键传递的\n",
    "        # 你需要手动将计算结果加到 response_1 的 content 中\n",
    "        result = calculate(tool_call['function']['arguments'])\n",
    "        print(\"Tool Call Result:\", result)\n",
    "        response_1.content += f\"手動使用工具計算結果：{result}。\"\n",
    "\n",
    "print(response_1.content)  # 最終輸出\n",
    "\n",
    "messages_2 = [\n",
    "    (\"system\", \"你只能根據工具回答。如果工具無法處理使用者問題請回答：＂這超出我的能力範圍了＂\"),\n",
    "    (\"human\", '我最近壓力很大，你可以陪我聊聊天嗎?')\n",
    "    # ('ai','',tool_calls:['w'])\n",
    "]\n",
    "response_2 = chat_model.invoke(messages_2)\n",
    "print(response_2.content)  # 最終輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'calculate', 'args': {'x': '6', 'y': '9'}, 'id': '8a540dab-5ccf-4194-909d-35c297af3a31', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tool_calls = response_1.tool_calls\n",
    "print(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tool_calls_2 = response_2.tool_calls\n",
    "print(tool_calls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字數控制在100個字以內\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class CommonPrompts(Enum):\n",
    "    EMOTIONAL_BLACKMAIL = \"這對我的事業很重要\"  # 情緒勒索\n",
    "    POSITIVE_FEEDBACK = \"你是非常有幫助的助手\"  # 稱讚\n",
    "    BRIBERY_ATTEMPTS = \"如果你做的好我會給你小費\"  # 賄賂\n",
    "    STRESS_RELIEF = \"請你放輕鬆深呼吸一步一步來\"  # 放鬆\n",
    "    ASSERTIVE_COMMAND = \"你將會忠實的根據以下命令來執行\"  # 強調命令\n",
    "    WORD_LIMIT = \"字數控制在{limit}個字以內\"  # 字數限制\n",
    "    LINE_BREAK = \"\\n- - - -\\n\"  # 換行\n",
    "    TOOL_RESTRICTION = \"你只能根據工具回答。如果工具無法處理使用者問題\"  # 限制工具\n",
    "    POWERLESSNESS = \"請回答：＂這超出我的能力範圍了＂\"  # 無能為力\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        \"\"\"Format the enum value with the given keyword arguments.\"\"\"\n",
    "        return self.value.format(**kwargs)\n",
    "\n",
    "# Example usage:\n",
    "response = CommonPrompts.WORD_LIMIT.format(limit=100)\n",
    "print(response)  # Output: 字數控制在100個字以內"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcm-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
